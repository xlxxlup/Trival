# 旅游项目面试准备指南

> 项目：基于LangGraph的多Agent旅游规划系统
> 核心架构：Plan-Execute-Replan三阶段循环 + 父子Agent协同 + ReAct推理模式

---

## 1. 工作流设计：Plan-Execute-Replan三阶段循环

### 面试问题
**"能详细介绍一下你的工作流设计吗？"**

### 回答要点

我设计了一个三阶段循环工作流，使用LangGraph构建状态图：

#### **Plan阶段** - 任务规划
- **位置**：`amusement_agent.py:158-436`
- **功能**：LLM分析用户需求，生成结构化任务规划
- **输出**：
  - `overview`：总体规划步骤
  - `actionable_tasks`：可执行的具体任务，按类别分组（交通、天气、酒店等）
  - `summary_task`: 总结任务，按类别分组（交通、天气、酒店等）
  - `intervention_request`：LLM自主判断是否需要人工介入
- **智能检测**：识别信息缺失，生成需要用户补充的问题

#### **Execute阶段** - 多Agent协同执行
- **位置**：`amusement_agent.py:438-632`
- **功能**：父Agent协调6个子Agent执行任务
- **流程**：
  1. 父Agent分析每个任务，决定分发给哪个子Agent
  2. 子Agent执行具体的工具调用（高德地图、12306等MCP服务）
  3. 子Agent判断任务是否完成
  4. 结合任务、工具结果进行总结
- **结果**：收集所有工具调用的结果

#### **Replan阶段** - 生成攻略并智能检测
- **位置**：`amusement_agent.py:785-1148`
- **功能**：基于执行结果生成旅游攻略
- **输出**：
  - 生成完整的旅游攻略（景点、美食、交通、天气等）
  - `need_supplement`：布尔值，标识是否需要补充执行，如果需要，给出原因
  - `supplement_tasks`：按类别分组的补充任务列表
- **智能检测**：分析攻略完整性，检测缺失信息

#### **闭环机制**
- 如果Replan检测到信息缺失 → 返回`need_supplement=True`
- 触发补充执行循环 → 回到Execute阶段执行补充任务
- 再次Replan → 直到信息完整或达到最大补充次数

**代码位置**：
- Plan阶段：[amusement_agent.py:158-436](backend/agent/amusement_agent.py#L158-L436)
- Execute阶段：[amusement_agent.py:438-632](backend/agent/amusement_agent.py#L438-L632)
- Replan阶段：[amusement_agent.py:785-1148](backend/agent/amusement_agent.py#L785-L1148)
- 补充循环检查：[amusement_agent.py:1275-1326](backend/agent/amusement_agent.py#L1275-L1326)

---

## 2. 多Agent协同架构：父Agent + 6个子Agent

### 面试问题
**"你的多Agent架构是怎么设计的？父Agent和子Agent如何协作？"**

### 回答要点

#### **父Agent职责**
- **位置**：`amusement_agent.py:660-783`
- **核心功能**：
  1. **任务分发**：使用LLM分析任务内容，决定分发给哪个子Agent
  2. **结果整合**：收集所有子Agent的工具调用结果
  3. **工作流协调**：控制整个Plan-Execute-Replan流程

**任务分发逻辑**：父Agent调用LLM分析任务内容，匹配可用的子Agent类型（交通/天气/地图/搜索/酒店/文件），LLM返回JSON格式的决策，包含选中的Agent类型和原因。

**降级策略**：如果LLM分析失败，使用关键词匹配（如"火车/机票"→transport）

**代码位置**：[sub_agents.py:664-878](backend/agent/sub_agents.py#L664-L878)

#### **MCP映射配置**
- **位置**：`config/mcp.py:63-73`
- **设计理念**：按MCP服务器类型绑定工具，而非硬编码工具名称

**MCP映射配置示例**：
- 12306-mcp → transport（交通助手）
- variflight-mcp → transport（机票工具）
- mcp_tool → weather（天气助手）
- amap-maps → map（地图助手）
- aigohotel-mcp → hotel（酒店助手）

#### **协同流程**
```
Execute阶段启动
    ↓
父Agent获取任务列表（按类别分组）
    ↓
遍历每个任务类别
    ↓
父Agent调用LLM分析任务 → 选择子Agent
    ↓
子Agent执行任务（多轮工具调用）
    ↓
父Agent收集工具结果
    ↓
传递给Replan阶段生成攻略
```

**代码位置**：
- 父Agent分发：[amusement_agent.py:660-783](backend/agent/amusement_agent.py#L660-L783)
- 子Agent定义：[sub_agents.py:36-878](backend/agent/sub_agents.py#L36-L878)
- MCP配置：[config/mcp.py](backend/config/mcp.py)

---

## 3. ReAct推理模式：思考-行动-观察循环

### 面试问题
**"你提到的ReAct推理模式是怎么实现的？"**

### 回答要点

我实现了**两层ReAct循环**：

#### **第一层：父Agent的任务分发**

**思考**：
- 父Agent使用LLM分析任务内容
- 推理应该由哪个子Agent处理（交通/天气/地图等）
- 返回JSON决策：`{"selected_agent": "transport", "reason": "任务涉及火车票查询"}`

**行动**：
- 将任务分发给选中的子Agent执行

**观察**：
- 收集子Agent的执行结果

#### **第二层：子Agent的工具调用循环**

**位置**：`sub_agents.py:126-365`

##### **1. 思考 - 推理工具选择**
子Agent调用LLM分析任务，决定调用哪个工具（如search_trains），LLM返回工具调用决策。

##### **2. 行动 - 执行工具调用**
根据LLM决策执行具体的工具调用（如调用12306-mcp的search_trains），获取工具返回结果。

##### **3. 观察 - 判断任务完成度**
使用专门的Prompt让LLM批判结果是否真正满足任务要求，返回格式：0|未完成原因 或 1|完成原因。

**关键创新**：不是简单检查是否有工具调用，而是使用LLM批判结果是否真正满足任务要求。

#### **ReAct循环示例**

```
第1轮循环：
┌─ 思考 ─┐ LLM分析："查询北京到上海的火车票"
│        │ → 决定调用：search_trains工具
└───────┘
     ↓
┌─ 行动 ─┐ 调用12306-mcp的search_trains
│        │ → 返回：车次、时间、部分价格信息
└───────┘
     ↓
┌─ 观察 ─┐ LLM批判结果
│        │ → 判断："缺少二等座票价信息"
└───────┘
     ↓
任务未完成 → 进入第2轮

第2轮循环（补充）：
┌─ 思考 ─┐ LLM接收反馈："缺少二等座票价"
│        │ → 决定再次查询：search_trains（详细票价）
└───────┘
     ↓
┌─ 行动 ─┐ 再次调用search_trains
│        │ → 返回：完整的票价信息
└───────┘
     ↓
┌─ 观察 ─┐ LLM再次批判
│        │ → 判断："任务已完成"
└───────┘
```

#### **额外轮次机制**
- 位置：`sub_agents.py:229-328`
- 触发条件：主循环结束后任务仍未完成
- 最多额外2轮
- 每轮都会告知LLM未完成的原因，引导其精准补充

#### **Fallback机制**
- 位置：`sub_agents.py:336-364`
- 触发条件：2轮额外轮次后仍未完成
- 行动：调用`zhipu_search`作为最后的fallback
- 智能query构建：基于任务和未完成原因生成搜索关键词

**代码位置**：
- 父Agent分发（思考）：[amusement_agent.py:660-783](backend/agent/amusement_agent.py#L660-L783)
- 子Agent ReAct循环：[sub_agents.py:126-365](backend/agent/sub_agents.py#L126-L365)
- 任务完成度检查（观察）：[sub_agents.py:433-514](backend/agent/sub_agents.py#L433-L514)
- Fallback机制：[sub_agents.py:516-649](backend/agent/sub_agents.py#L516-L649)

---

## 4. 工具集成：6种MCP服务

### 面试问题
**"你集成了哪些MCP工具？如何统一调用接口？"**

### 回答要点

#### **集成的6种MCP服务**

| MCP服务 | 功能 | 传输方式 | 认证 | 绑定Agent |
|---------|------|---------|------|----------|
| **amap-maps** | POI搜索、路线规划 | SSE | 无 | 地图助手 |
| **12306-mcp** | 火车票时刻、价格查询 | streamable_http | 无 | 交通助手 |
| **variflight-mcp** | 航班信息查询 | SSE | 无 | 交通助手 |
| **mcp_tool** | 天气预报查询 | SSE | 无 | 天气助手 |
| **aigohotel-mcp** | 酒店搜索、价格对比 | streamable_http | Authorization | 酒店助手 |
| **zhipu_search** | 互联网搜索 | 本地工具 | 无 | 搜索助手（fallback） |

**配置位置**：`config/mcp.py:3-58`

#### **统一调用接口**

**MCPManager单例管理**：
- 位置：`utils/mcp_manager.py`
- 功能：
  - 自动连接所有配置的MCP服务器
  - 按服务器分组工具：`get_tools_by_server()`
  - 根据配置映射创建子Agent：`create_sub_agents()`

**工具调用流程**：
1. 从MCP管理器获取工具（按服务器分组）
2. 根据配置创建子Agent并绑定工具
3. 子Agent执行时调用工具，获取结果并存储

#### **工具调用结果存储**
每次工具调用后自动保存到JSON文件：
- 按类别分类（transport、hotel、weather等）
- 存储工具输入、输出、上下文信息
- 用于缓存复用和后续RAG检索

**代码位置**：
- MCP配置：[config/mcp.py](backend/config/mcp.py)
- MCP管理器：[utils/mcp_manager.py](backend/utils/mcp_manager.py)
- 工具调用执行：[utils/agent_tools.py](backend/utils/agent_tools.py)

---

## 5. 智能缓存机制：工具结果缓存与复用

### 面试问题
**"你是如何实现缓存机制的？如何避免重复调用？"**

### 回答要点

#### **缓存存储策略**

**位置**：`utils/tool_data_storage.py`

**分类存储**：
- 按任务类别分别存储到JSON文件：`transport.json`、`hotel.json`、`weather.json`
- 每个工具执行结果保存为一条记录

**存储结构**：每条记录包含时间戳、类别、工具名称、工具输入/输出、执行上下文、元数据（任务描述、Agent名称、执行轮次）。

#### **保存时机**

每次工具调用后立即保存：保存工具名称、输入参数、输出结果、执行上下文到对应类别的JSON文件中。

#### **缓存复用策略**

**位置**：`tool_data_storage.py:286-339`

支持两种匹配模式：

1. **精确匹配**（`require_exact_match=True`）：
   - tool_input必须完全相同
   - 适用于对参数敏感的场景

2. **模糊匹配**（默认）：
   - 过滤空值参数（None、""）
   - 只比较非空参数是否相同
   - 示例：{"city": "北京", "keywords": ""} 和 {"city": "北京"} 被视为相同，因为空字符串被过滤

#### **缓存优势**

1. **降低API成本**：避免重复调用相同的MCP服务
2. **减少响应延迟**：直接从本地JSON文件读取（毫秒级）
3. **支持RAG检索**：按上下文条件查询历史执行记录
4. **数据分析**：可以分析工具使用频率和成功率

#### **查询示例**
查找匹配的缓存记录时，指定类别、工具名称、工具输入参数，系统会自动匹配并返回缓存结果，跳过实际工具调用。

**代码位置**：
- 缓存存储：[utils/tool_data_storage.py](backend/utils/tool_data_storage.py)
- 保存逻辑：[sub_agents.py:196-221](backend/agent/sub_agents.py#L196-L221)
- 缓存查找：[tool_data_storage.py:286-339](backend/utils/tool_data_storage.py#L286-L339)

---

## 6. 反馈调整机制：增量优化与智能合并

### 面试问题
**"用户反馈后如何调整计划？如何避免全量重新生成？"**

### 回答要点

#### **反馈模式触发**

**流程**：
1. 用户对生成的旅游攻略不满意
2. 提交反馈（如"酒店推荐太少了"、"调整餐饮预算"）
3. 系统设置`is_feedback_mode=True`
4. 重新进入Plan/Replan阶段

#### **增量优化策略**

**Plan阶段的增量优化**：
- **位置**：`amusement_agent.py:222-252`
- **专用Prompt**：`AMUSEMENT_SYSTEM_PLAN_FEEDBACK_TEMPLATE`
- **输入**：
  - 用户反馈内容
  - 原始计划摘要
- **输出**：只生成调整相关的任务，不重复规划已完成的部分

**Replan阶段的增量优化**：
- **位置**：`amusement_agent.py:867-898`
- **专用Prompt**：`AMUSEMENT_SYSYRM_REPLAN_FEEDBACK_TEMPLATE`
- **输入**：
  - 用户反馈内容
  - 完整的原始`amusement_info`（JSON格式）
- **输出**：只调整用户不满意的特定部分

#### **智能合并策略**

**位置**：`amusement_agent.py:1004-1079`

**核心理念**：保留原始信息为基础，只合并LLM返回的改进部分

**合并策略**：
1. 空值跳过：LLM返回空值时保留原始数据
2. 复杂字段深度合并：transportation、accommodation等字段只更新有值的子字段
3. 内容丰富度比较：对于list/dict字段，比较长度，保留内容更丰富的版本
4. 其他字段直接更新：用户明确提到的部分直接使用新数据

#### **合并示例**

**原始攻略**：包含6个景点、2个餐厅

**用户反馈**：景点太多了，去掉几个，多推荐几家餐厅

**LLM返回**：2个景点、4个餐厅

**智能合并结果**：
- destination：保留原始
- attractions：使用新数据（2个 < 6个，采纳用户精简需求）
- restaurants：使用新数据（4个 > 2个，采纳用户扩充需求）

#### **效率提升**

- **避免全量重新生成**：节省Token成本约60-70%
- **保留未调整部分**：原始信息的详细程度不会被降低
- **精准修改**：只调整用户不满意的特定部分
- **上下文保留**：用户未提到的部分保持不变

**代码位置**：
- Plan反馈模式：[amusement_agent.py:162-252](backend/agent/amusement_agent.py#L162-L252)
- Replan反馈模式：[amusement_agent.py:789-1079](backend/agent/amusement_agent.py#L789-L1079)
- 智能合并逻辑：[amusement_agent.py:1004-1079](backend/agent/amusement_agent.py#L1004-L1079)

---

## 7. 智能交互机制：人工介入判断

### 面试问题
**"系统如何判断需要人工介入？支持哪些交互方式？"**

### 回答要点

#### **LLM自主判断机制**

**位置**：`amusement_agent.py:219-416`（Plan阶段）、`amusement_agent.py:1105-1130`（Replan阶段）

**结构化输出**：使用`PlanWithIntervention`和`ReplanWithIntervention`格式，让LLM返回是否需要介入，以及介入的具体问题、选项类型、是否允许多选等配置。

**判断依据**：
- 用户需求不够具体（如"预算充足"但没有具体金额）
- 存在多个合理的选择（如交通方式、住宿区域）
- 需要用户偏好（如文化历史 vs 自然风光）

#### **支持的交互方式**

**位置**：`formatters/amusement_format.py`

| 交互类型 | 字段配置 | 用户操作 | 示例 |
|---------|---------|---------|------|
| **文本输入** | `allow_text_input: true` | 自由输入文字 | "预算5000元" |
| **单选** | `multi_select: false`<br>`options: [...]` | 选择一个选项 | 选择"高铁" |
| **多选** | `multi_select: true`<br>`options: [...]` | 选择多个选项 | 选择["文化历史", "美食"] |
| **确认对话框** | `options: ["继续", "重新规划"]` | 确认或取消 | 选择"继续" |

#### **人工介入流程**

**完整流程图**：
```
Plan/Replan阶段
    ↓
LLM判断：need_intervention?
    ↓
YES → 设置intervention_stage = "plan" 或 "replan"
    ↓
跳转到 wait_user_plan / wait_user_replan 节点
    ↓
流程暂停，状态保存到数据库
    ↓
返回session_id给前端
    ↓
用户在前端看到问题并回答
    ↓
前端调用 /resume 接口，传入session_id和用户答案
    ↓
后端更新state的intervention_response
    ↓
重新调用graph.ainvoke(state)
    ↓
resume_router根据intervention_stage决定恢复位置
    ↓
重新执行Plan/Replan（这次会处理用户的答案）
    ↓
继续后续流程
```

**代码位置**：
- 检查介入：[amusement_agent.py:1388-1456](backend/agent/amusement_agent.py#L1388-L1456)
- 暂停节点：[amusement_agent.py:1416-1428](backend/agent/amusement_agent.py#L1416-L1428)
- 路由恢复：[amusement_agent.py:1329-1386](backend/agent/amusement_agent.py#L1329-L1386)

#### **避免过度介入**

**策略**：
1. **记录历史问答**：将每次介入的问题和答案保存到`collected_info["asked_questions"]`
2. **传递给LLM**：Plan/Replan阶段可以看到所有历史问答
3. **智能避免重复**：LLM能看到之前已经问过的问题，避免重复提问

#### **多轮交互支持**

- 不限制介入次数（通过`intervention_count`追踪但不强制限制）
- 每次介入后，用户的答案会被记录
- 下一轮Plan/Replan可以看到完整的历史问答
- 支持在不同阶段介入（Plan阶段、Replan阶段）

**代码位置**：
- 介入判断：[amusement_agent.py:394-416](backend/agent/amusement_agent.py#L394-L416)
- 问题记录：[amusement_agent.py:405-414](backend/agent/amusement_agent.py#L405-L414)
- 历史问答格式化：[amusement_agent.py:259-267](backend/agent/amusement_agent.py#L259-L267)

---

## 8. 上下文管理：消息压缩算法

### 面试问题
**"如何控制Token消耗？消息压缩策略是什么？"**

### 回答要点

#### **消息压缩函数**

**位置**：`amusement_agent.py:67-157`

#### **核心策略**

```
原始消息（50条）
    ↓
分类：ToolMessage(30条) + 其他消息(20条)
    ↓
保留所有ToolMessage（最重要，不能丢失）
    ↓
保留最近N条其他消息（默认5-10条）
    ↓
旧消息 → LLM总结 → 1条总结消息
    ↓
压缩后：1条总结 + 30条ToolMessage + 5条最近 = 36条
    ↓
Token节省：约30-40%
```

#### **压缩流程详解**

**步骤1：分类消息**：将消息分为ToolMessage（工具调用结果）和其他消息（Human/AI/System消息）

**步骤2：保留最近消息**：保留最近5-10条其他消息，其余标记为旧消息

**步骤3：LLM总结旧消息**：使用LLM将旧对话历史总结为简洁概要，保留关键信息

**步骤4：组合压缩后的消息**：总结消息 + 所有ToolMessage + 最近其他消息

#### **分场景压缩阈值**

| 场景 | 压缩阈值 | 原因 |
|------|---------|------|
| **正常Plan阶段** | `max_messages=15` | 平衡上下文完整性和成本 |
| **反馈模式Plan** | `max_messages=5` | 只需关注反馈内容，减少历史 |
| **正常Replan阶段** | `max_messages=15` | 需要工具结果，但不需要太多对话历史 |
| **反馈模式Replan** | `max_messages=20` | 需要完整上下文理解用户意图 |

#### **降级策略**

如果LLM总结失败，则使用简单截断策略：只保留ToolMessage和最近的其他消息，丢弃旧消息。

#### **压缩效果示例**

**原始**：50条消息
- ToolMessage: 30条（工具调用结果）
- HumanMessage: 10条（用户输入）
- AIMessage: 10条（AI响应）

**压缩后**：36条消息
- SystemMessage: 1条（历史对话总结，约200字）
- ToolMessage: 30条（完整保留）
- 最近消息: 5条（3条HumanMessage + 2条AIMessage）

**Token对比**：
- 原始：约15,000 tokens
- 压缩后：约9,000 tokens
- 节省：约40%

#### **保证上下文完整性**

**三层保障**：
1. **ToolMessage完整保留**：工具调用结果最重要，不能丢失
2. **最近消息完整保留**：最新的5-10条对话保持完整
3. **旧消息被总结**：关键信息被LLM提炼成概要

**优势**：
- 大幅降低Token成本（30-40%）
- 保留最重要的工具结果
- 上下文连续性不受影响
- 支持超长对话（100+轮）

**代码位置**：
- 消息压缩函数：[amusement_agent.py:67-157](backend/agent/amusement_agent.py#L67-L157)
- Plan阶段调用：[amusement_agent.py:310](backend/agent/amusement_agent.py#L310)
- Replan阶段调用：[amusement_agent.py:923](backend/agent/amusement_agent.py#L923)

---

## 💡 面试话术建议

### 开场示例
"这个项目是一个基于LangGraph的多Agent旅游规划系统。我设计的核心创新点是**三阶段循环工作流**结合**多Agent协同架构**，实现了从需求分析到攻略生成的全自动化流程。项目最大的亮点是**ReAct推理模式**和**智能反馈调整机制**，能够动态补全信息并响应用户反馈。"

### 回答技术问题时的技巧

**当被问到具体实现**：
"让我结合代码具体说明一下。在`XXX文件的XXX行`，我实现了..."

**示例**：
"ReAct循环在`sub_agents.py`的`126-365行`实现。子Agent首先调用LLM分析任务（思考），然后决定调用哪个工具（行动），执行工具后使用专门的Prompt让LLM批判结果是否完整（观察），如果未完成则进入下一轮循环。"

**当被问到为什么这样设计**：
"这样设计主要考虑了3个方面：
1. **成本优化**：通过缓存、消息压缩、限制轮次来降低API调用成本
2. **准确性**：通过ReAct循环、任务完成度检查、fallback机制确保信息完整
3. **用户体验**：通过人工介入、反馈调整、智能合并提供个性化服务"

**当被问到遇到的挑战**：
"项目中最具挑战的是**如何平衡成本和质量**。我通过三个策略解决：
1. 设计了智能缓存机制，避免重复调用MCP服务
2. 实现了消息压缩算法，降低Token消耗30-40%
3. 为不同子Agent设置不同的最大轮次（交通/天气助手1轮，其他2轮）"

### 展示亮点时

**"我特别自豪的是XXX功能"**：

1. **ReAct推理模式**：
   "传统的Agent调用工具后就认为任务完成，但我设计了任务完成度检查机制，使用LLM批判结果是否真正满足需求，如果未完成会自动进入下一轮补充查询，这大大提高了信息的完整性。"

2. **智能反馈调整**：
   "很多系统在用户反馈后会全量重新生成，成本高且可能丢失原有信息。我设计了智能合并策略，基于内容丰富度比较，只更新用户不满意的特定部分，节省Token成本60-70%。"

3. **人工介入机制**：
   "系统不是被动等待用户提供所有信息，而是让LLM自主判断何时需要人工介入，支持文本输入、单选、多选等多种交互方式，并且会记录历史问答避免重复提问，大大提升了用户体验。"

### 数据量化

在回答中尽量使用具体数据：
- "降低Token消耗**30-40%**"
- "节省反馈调整成本**60-70%**"
- "支持**6种**MCP服务集成"
- "**最多2轮**额外ReAct循环"
- "**6个子Agent**协同工作"

### 展示系统思维

"这个项目不是简单的工具调用堆砌，而是一个完整的**闭环系统**：
- Plan阶段识别缺失 → Execute阶段补充 → Replan阶段再次检测 → 继续补充
- 用户反馈 → 增量调整 → 智能合并 → 保留优化
- 人工介入 → 暂停流程 → 用户响应 → 恢复执行

每个环节都有检测、反馈、调整机制，形成了一个自适应的智能系统。"

---


## 9. 短期上下文与长期上下文管理

### 面试问题
**"你的项目如何管理上下文？如何处理长对话？"**

### 回答要点

#### **短期上下文**

**定义**：当前对话/任务中最近的消息和状态，直接参与LLM推理的上下文。

**在项目中的体现**：
1. **最近N条消息**：消息压缩中保留的5-15条消息
2. **当前任务的工具调用结果**：所有ToolMessage
3. **用户当前的需求和反馈**：实时输入的内容
4. **Plan/Execute/Replan阶段的输入输出**：当前工作流状态

**特点**：
- 容量有限（受模型上下文窗口限制）
- 实时性强，直接影响当前任务决策
- 随对话进行而动态变化
- 每次LLM调用都会发送，Token成本高

#### **长期上下文**

**定义**：历史对话、知识库、缓存数据等持久化存储的信息，需要时可以检索和利用。

**在项目中的体现**：
1. **工具执行结果缓存**：JSON文件存储的transport.json、hotel.json、weather.json等
2. **历史问答记录**：`collected_info["asked_questions"]`记录所有介入问题
3. **用户反馈历史**：用于智能合并的原始攻略完整信息
4. **消息压缩后的总结**：将旧对话通过LLM总结为概要

**特点**：
- 容量可以很大（文件系统、数据库）
- 持久化存储，不会丢失
- 按需检索，加载到短期上下文
- 存储成本低，检索速度快

#### **短长期上下文的转换机制**

**1. 消息压缩算法（短期→长期）**：

```
原始短期上下文（50条消息）
    ↓
分类处理
    ↓
ToolMessage → 保留在短期上下文（最重要，不能丢失）
最近消息 → 保留在短期上下文（当前任务相关）
旧消息 → LLM总结 → 转为长期上下文（压缩总结）
    ↓
新的短期上下文（36条消息，节省30-40% Token）
```

**优势**：
- 降低Token消耗30-40%
- 保留关键信息不丢失
- 支持超长对话（100+轮）

**2. 缓存机制（长期→短期）**：

```
第一次查询"北京到上海火车票"
    ↓
调用MCP工具（消耗API和时间）
    ↓
保存到长期上下文（transport.json）
    ↓
第二次查询相同路线
    ↓
从长期上下文检索（毫秒级，零成本）
    ↓
加载到短期上下文使用
```

**优势**：
- 避免重复调用MCP服务
- 减少响应延迟（毫秒级 vs 秒级）
- 支持RAG检索历史记录

**3. 反馈调整（短长期协作）**：

```
长期上下文：原始完整攻略
  - 6个景点、2个餐厅、完整行程
  - 持久化存储，详细信息

短期上下文：用户反馈 + LLM调整
  - 用户："景点太多，餐厅太少"
  - LLM返回：2个景点、4个餐厅

智能合并：保留长期上下文的详细信息，融入短期上下文的调整
  - destination：保留原始（长期）
  - attractions：使用新数据（短期，2<6）
  - restaurants：使用新数据（短期，4>2）
```

**优势**：
- 避免全量重新生成（节省60-70% Token）
- 保留未调整部分的详细信息
- 精准修改用户不满意的特定部分

#### **为什么要区分短期和长期上下文**

**1. 成本优化**：
- **短期上下文**：每个请求都要发送给LLM，Token成本高
- **长期上下文**：存储成本低（JSON文件），需要时才加载

**项目效果**：
- 消息压缩节省30-40% Token
- 缓存避免重复MCP调用

**2. 上下文窗口限制**：
- 模型上下文窗口有限（如8K、32K、128K）
- 长期上下文可以无限扩展
- 只把需要的部分加载到短期上下文

**项目实现**：
- 工具调用结果完整保留在短期上下文（重要）
- 历史对话总结后放入短期上下文（压缩）
- 完整历史保存在长期上下文（可检索）

**3. 性能优化**：
- **短期上下文**：实时推理，速度快
- **长期上下文**：检索可以并行，不影响推理速度

**项目对比**：
- 缓存命中：直接返回（毫秒级）
- MCP调用：工具执行（秒级）

#### **面试回答示例**

**"在我的项目中，我设计了完善的短期和长期上下文管理策略：**

**短期上下文管理**：
- 包含最近15条消息和所有工具调用结果
- 直接参与LLM推理，影响当前任务决策
- 通过消息压缩算法动态控制大小
- 节省Token消耗30-40%

**长期上下文管理**：
- 包含历史工具执行结果（JSON文件缓存）
- 存储用户历史问答和反馈记录
- 支持RAG检索，按需加载到短期上下文
- 容量无限扩展，持久化存储

**两者协作机制**：
1. 查询信息时，先检索长期上下文（缓存），未命中才调用工具
2. 工具调用结果同时存入短期和长期上下文
3. 旧对话通过LLM总结，从短期转为长期上下文
4. 用户反馈时，长期上下文提供完整信息，短期上下文承载调整

**这样设计带来的价值**：
1. 降低Token消耗（消息压缩、缓存复用）
2. 减少API调用成本（避免重复MCP调用）
3. 支持超长对话（长期上下文无限扩展）
4. 保证信息完整性（重要数据不丢失）

**代码位置**：
- 消息压缩（短期→长期）：[amusement_agent.py:67-157](backend/agent/amusement_agent.py#L67-L157)
- 缓存存储（长期上下文）：[tool_data_storage.py](backend/utils/tool_data_storage.py)
- 缓存检索（长期→短期）：[tool_data_storage.py:286-339](backend/utils/tool_data_storage.py#L286-L339)
- 智能合并（短长期协作）：[amusement_agent.py:1004-1079](backend/agent/amusement_agent.py#L1004-L1079)"

---

**最后建议**：
1. 熟读代码，理解每个模块的实现细节
2. 准备1-2个具体的用户场景示例，能够从头到尾讲解流程
3. 思考项目的可扩展性（如何添加新的MCP服务、新的子Agent等）
4. 准备好回答"如果让你重新设计，你会怎么改进"这类问题
5. 理解短期上下文和长期上下文的管理策略，这是系统设计的关键

祝你面试顺利！🚀
